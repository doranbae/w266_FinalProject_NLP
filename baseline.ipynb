{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "# Prepare data for baseline\n",
    "#\n",
    "# Source: IMSDb\n",
    "# This script extracts and prepares screenplay text data ready for machine learning.\n",
    "# - Scrapes screenplay text data from IMSDb\n",
    "# - Data cleaning and text preprocessing\n",
    "#   - Removing HTML Markup: The Beautiful Soup package\n",
    "#   - Dealing with punctuation, numbers and stopwords\n",
    "# - Put it back all together\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from BeautifulSoup import BeautifulSoup  # I'm using version 3.2.1 BeautifulSoup version 4 has different syntax\n",
    "from collections import Counter\n",
    "import urllib\n",
    "import importlib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class preprocessing:\n",
    "    def __init__(self):\n",
    "        self.y = []             # y labels: global box-office for each movie\n",
    "        self.x = []             # x input: screenplay text\n",
    "        self.title_list =[]     # look-up movie titles for each x value\n",
    "        self.tmp_y = []\n",
    "        self.tmp_title_list = []\n",
    "        self.fail_screenplay = 0\n",
    "        self.success_screenplay = 0\n",
    "        self.y = []\n",
    "\n",
    "    def create_label_data(self):\n",
    "        with open(\"movie_data.csv\", 'r') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            for row in reader:\n",
    "                self.tmp_title_list.append(row[0]) \n",
    "                self.tmp_y.append(row[1])\n",
    "            print(\"Started with %f total movie lists\" %len(self.tmp_title_list))\n",
    "            #print(\"Created label data of %f y value\" %len(self.tmp_y))\n",
    "\n",
    "    def create_input_data(self):  # Go through the title list and scrape screenplay text\n",
    "        for m in self.tmp_title_list:\n",
    "            self.x.append(preprocessing.scrape_screenplay(self,m))\n",
    "        # Filter out none values\n",
    "        self.x = filter(lambda a: a != 0, self.x)\n",
    "        #print(\"Scraped and saved: %f screenplay\" %len(self.x))\n",
    "        #print(\"Scraped and saved: %f titles\" % len(self.title_list))\n",
    "        #print(\"Titles:\", self.title_list) # Check movie titles which screenplays aren't available\n",
    "        print(\"Success movies: \", self.success_screenplay)\n",
    "        print(\"Fail movies: \", self.fail_screenplay)\n",
    "\n",
    "    def scrape_screenplay(self, movie_title):\n",
    "        try:\n",
    "            url = 'http://www.imsdb.com/scripts/%s.html' % movie_title\n",
    "            page = urllib.urlopen(url)\n",
    "            soup = BeautifulSoup(page.read())\n",
    "            rawtext = str(soup.find(\"td\", {\"class\": \"scrtext\"}))\n",
    "            clean = rawtext.lower()\n",
    "            clean = re.sub('<[^<]+?>','',clean)\n",
    "            words = clean.split()\n",
    "            if len(words) > 200:\n",
    "                self.success_screenplay += 1\n",
    "                #print(self.tmp_title_list.index(movie_title))\n",
    "                #print(self.tmp_y[self.tmp_title_list.index(movie_title)])\n",
    "                self.y.append(self.tmp_y[self.tmp_title_list.index(movie_title)]) # Find the value from the temp list\n",
    "                self.title_list.append(movie_title)\n",
    "                results = \" \".join(words)\n",
    "                return results\n",
    "            else: \n",
    "                self.fail_screenplay += 1\n",
    "                #print(\"%s movie screenplay is not available\" %movie_title)\n",
    "                return 0\n",
    "        except:  # If movie URL is dead, skip it\n",
    "            pass\n",
    "        \n",
    "    def hit_or_flop(self):\n",
    "        # Defines hit or flop scale:\n",
    "        #  5: blockbuster, 400M ~ above, ex. Finding Dory, Star Wars\n",
    "        #  4: hit, 200M ~ 400M, ex. Ghostbusters, King Kong\n",
    "        #  3: average, 100M ~ 200M, ex. Bridesmaid, Sleepless in Seattle\n",
    "        #  2: flop, 50M ~ 100M, ex. Sin City, Splash\n",
    "        #  1: disaster, ~50M, ex. who cares...\n",
    "        #self.y = self.y[:-1] #BUG: I don't know why there is extra here.\n",
    "        for idx,b in enumerate(self.y):\n",
    "            if self.y[idx] > '400000000':\n",
    "                self.y[idx] = 5\n",
    "            elif self.y[idx] > '200000000' and self.y[idx] < '400000000':\n",
    "                self.y[idx] = 4\n",
    "            elif self.y[idx] > '100000000' and self.y[idx] < '200000000' :\n",
    "                self.y[idx] = 3\n",
    "            elif self.y[idx] > '50000000' and self.y[idx] < '100000000':\n",
    "                self.y[idx] = 2\n",
    "            elif self.y[idx] < '50000000' :\n",
    "                self.y[idx] = 1\n",
    "        #print(self.y) # Check y values are changed.\n",
    "\n",
    "    def split_train_test(self,train_portion):\n",
    "        self.train_set_x = self.x[:train_portion]\n",
    "        self.test_set_x = self.x[train_portion:]\n",
    "        self.train_set_y = self.y[:train_portion]\n",
    "        self.test_set_y = self.y[train_portion:]\n",
    "        print(\"Train set %f\" %len(self.train_set_x))\n",
    "        print(\"Test set %f\" % len(self.test_set_x))\n",
    "\n",
    "    def feature_extraction(self):\n",
    "        vectorizer = CountVectorizer(analyzer= 'word',\n",
    "                                     tokenizer= None,\n",
    "                                     preprocessor= None,\n",
    "                                     stop_words= 'english',\n",
    "                                     max_features= 500)\n",
    "\n",
    "        self.train_data_features = vectorizer.fit_transform(self.train_set_x)\n",
    "        self.train_data_features = self.train_data_features.toarray()\n",
    "        \n",
    "        self.test_data_features = vectorizer.fit_transform(self.test_set_x)\n",
    "        self.test_data_features = self.test_data_features.toarray()\n",
    "        print(\"Training data array looks like this:\", self.train_data_features.shape)\n",
    "        print(\"Test data array looks like this:\", self.test_data_features.shape)\n",
    "\n",
    "    def train_randomForest(self):\n",
    "        # Initialize RF with 100 trees\n",
    "        forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "        # Fit the forest to the training set, using the bag of words as features\n",
    "        # and box office labels as the response variable\n",
    "\n",
    "        self.forest = forest.fit(self.train_data_features, self.train_set_y)\n",
    "        print(\"Finished training the data\")\n",
    "\n",
    "    def make_prediction(self): \n",
    "        self.result = self.forest.predict(self.test_data_features)\n",
    "        self.output = pd.DataFrame(data={\"box-office\": self.result})\n",
    "        print(self.output)\n",
    "    \n",
    "    def score(self):\n",
    "        self.pscore = metrics.accuracy_score(self.test_set_y, self.result)\n",
    "        #self.pscore_train = metrics.accuracy_score(y_train, pred_train)\n",
    "        print(self.pscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with 1513.000000 total movie lists\n",
      "('Success movies: ', 195)\n",
      "('Fail movies: ', 1318)\n"
     ]
    }
   ],
   "source": [
    "job = preprocessing()\n",
    "job.create_label_data()\n",
    "job.create_input_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "job.hit_or_flop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 150.000000\n",
      "Test set 45.000000\n"
     ]
    }
   ],
   "source": [
    "# Split train and test set. Argument is the count of movie titles for train dataset.\n",
    "job.split_train_test(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training data array looks like this:', (150, 500))\n",
      "('Test data array looks like this:', (45, 500))\n"
     ]
    }
   ],
   "source": [
    "job.feature_extraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training the data\n"
     ]
    }
   ],
   "source": [
    "job.train_randomForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    box-office\n",
      "0            5\n",
      "1            5\n",
      "2            5\n",
      "3            5\n",
      "4            5\n",
      "5            5\n",
      "6            5\n",
      "7            5\n",
      "8            5\n",
      "9            4\n",
      "10           5\n",
      "11           5\n",
      "12           4\n",
      "13           5\n",
      "14           5\n",
      "15           5\n",
      "16           5\n",
      "17           5\n",
      "18           5\n",
      "19           3\n",
      "20           5\n",
      "21           5\n",
      "22           5\n",
      "23           5\n",
      "24           5\n",
      "25           5\n",
      "26           5\n",
      "27           5\n",
      "28           5\n",
      "29           5\n",
      "30           5\n",
      "31           5\n",
      "32           5\n",
      "33           5\n",
      "34           5\n",
      "35           5\n",
      "36           5\n",
      "37           5\n",
      "38           5\n",
      "39           5\n",
      "40           5\n",
      "41           4\n",
      "42           5\n",
      "43           5\n",
      "44           3\n"
     ]
    }
   ],
   "source": [
    "job.make_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333333333\n"
     ]
    }
   ],
   "source": [
    "job.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bean',\n",
       " 'American-Sniper',\n",
       " 'Gladiator',\n",
       " 'Extract',\n",
       " 'Colombiana',\n",
       " 'Argo',\n",
       " 'Django-Unchained',\n",
       " 'Limitless',\n",
       " 'Life-of-Pi',\n",
       " 'Funny-People',\n",
       " 'Dragonslayer',\n",
       " 'Despicable-Me-2',\n",
       " 'Deception',\n",
       " 'Buried',\n",
       " 'Big-Fish',\n",
       " 'Crank',\n",
       " 'Cliffhanger',\n",
       " 'Collateral-Damage',\n",
       " 'In-the-Bedroom',\n",
       " 'Lake-Placid',\n",
       " 'Gamer',\n",
       " 'Insidious',\n",
       " 'Bad-Boys',\n",
       " 'Dallas-Buyers-Club',\n",
       " 'E.T.',\n",
       " 'Larry-Crowne',\n",
       " 'Field-of-Dreams',\n",
       " \"Malibu's-Most-Wanted\",\n",
       " 'Beasts-of-the-Southern-Wild',\n",
       " 'Collateral',\n",
       " 'Lincoln',\n",
       " 'Dumb-and-Dumber',\n",
       " 'Hostage',\n",
       " 'Burn-After-Reading',\n",
       " 'Disturbia',\n",
       " 'Go',\n",
       " 'King-Kong',\n",
       " 'Finding-Nemo',\n",
       " 'Dogma',\n",
       " 'Backdraft',\n",
       " 'Enough',\n",
       " 'Inception',\n",
       " '2001-A-Space-Odyssey',\n",
       " 'Easy-A',\n",
       " 'Liar-Liar']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.title_list[:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
